{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing inference with SageMaker Built-in Object Detection model\n",
    "\n",
    "1. [Download the trained model artifact](#download)\n",
    "1. [Convert training model to deployable model](#convert)\n",
    "1. [Inference](#inference)\n",
    "  1. [model load](#load)\n",
    "  1. [single image inference](#singleinference)\n",
    "  1. [batch inference](#batchinference)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup\n",
    "### conda_mxnet_p36 is required kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gluoncv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import json\n",
    "import boto3\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='deeplens-imageclassification-matthew'\n",
    "endEpoch=60\n",
    "TMP_FOLDER = 'trained-model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running this script, you need to make sure that command line options you pass in match exactly the hyperparameters of your training job. If youâ€™re unsure, refer the hyperparams.json file in your unpacked model artifacts to confirm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the copy of the deployable model artifact in S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Doing inference with the model on local host <a id='inference'></a>\n",
    "\n",
    "Below code will run inference on a set of test images on the current notebook instance. Using a GPU instance (e.g. p2.\\*, p3.\\* family) will result in faster performance than CPU only instances. You can stop the SageMaker notebook instance and update the instance type, and restart the notebook instance before continuing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cpu(0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ctx():\n",
    "    try:\n",
    "        gpus = mx.test_utils.list_gpus()\n",
    "        if len(gpus) > 0:\n",
    "            ctx = []\n",
    "            for gpu in gpus:\n",
    "                ctx.append(mx.gpu(gpu))\n",
    "        else:\n",
    "            ctx = [mx.cpu()]\n",
    "    except:\n",
    "        ctx = [mx.cpu()]\n",
    "    return ctx\n",
    "\n",
    "ctx = get_ctx()[0]\n",
    "ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = 224\n",
    "input_shapes=[('data', (1, 3, SHAPE, SHAPE))]\n",
    "confidence_threshold = 0.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3A. Loading the model <a id=\"load\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param_path: trained-model/image-classification\n",
      "100\n",
      "200\n",
      "300\n",
      "CPU times: user 122 ms, sys: 80.9 ms, total: 203 ms\n",
      "Wall time: 154 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_path=os.path.join(TMP_FOLDER, 'image-classification')\n",
    "print(\"param_path: {}\".format(param_path))\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint(param_path, endEpoch)#matthew : 60 is the latest epoch\n",
    "#print(arg_params)\n",
    "#print(sym)\n",
    "#print(aux_params)\n",
    "print(100)\n",
    "mod = mx.mod.Module(symbol=sym, label_names=[], context = ctx)\n",
    "print(200)\n",
    "mod.bind(for_training=False, data_shapes=input_shapes, label_shapes = None)\n",
    "print(300)\n",
    "# Create module\n",
    "#model = mx.mod.Module(symbol = mx_sym, context = mx.cpu(), label_names=[])\n",
    "\n",
    "# Bind the data shape and load params\n",
    "#model.bind(for_training=False,\n",
    "#           data_shapes = [('data',(1,3,224,224))],\n",
    "#           label_shapes = None))\n",
    "#model.set_params(args, auxs)\n",
    "\n",
    "mod.set_params(arg_params, aux_params, allow_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Batch = namedtuple('Batch', ['data'])\n",
    "\n",
    "def predict_from_file(filepath, reshape=(SHAPE, SHAPE)):\n",
    "    # Switch RGB to BGR format (which ImageNet networks take)\n",
    "    img = cv2.cvtColor(cv2.imread(filepath), cv2.COLOR_BGR2RGB)\n",
    "    if img is None:\n",
    "        return []\n",
    "\n",
    "     # Resize image to fit network input\n",
    "    img = cv2.resize(img, reshape)\n",
    "    \n",
    "    org_image = img.copy()\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    img = np.swapaxes(img, 1, 2)\n",
    "    img = img[np.newaxis, :]\n",
    " \n",
    "    mod.forward(Batch([mx.nd.array(img)]))\n",
    "    prob = mod.get_outputs()[0].asnumpy()\n",
    "    prob = np.squeeze(prob)\n",
    "\n",
    "    return prob, org_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(image_path, threshold=confidence_threshold):\n",
    "    results, org_image = predict_from_file(image_path)\n",
    "    image_name = image_path.split(\"/\")[-1]\n",
    "    print(results)\n",
    "    maxId=np.argmax(results)\n",
    "    strDet=''\n",
    "    if maxId==0 and results[maxId] > 0.9:\n",
    "        strDet='cat'\n",
    "    elif maxId==1 and results[maxId] > 0.9 :\n",
    "        strDet='dog'  \n",
    "    else :\n",
    "        strDet='other'\n",
    "\n",
    "    \n",
    "    return strDet, results[maxId]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3B. Test inference on single image <a id=\"singleinference\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.9991298e-01 8.6768858e-05 2.8140613e-07]\n",
      "cat\n",
      "0.999913\n",
      "CPU times: user 384 ms, sys: 136 ms, total: 520 ms\n",
      "Wall time: 434 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prediction_image = 'img/Taka_Shiba.jpg'\n",
    "#prediction_image = 'img/1280px-Danish_bicycle_female.jpg'\n",
    "prediction_image = 'img/img_1317.jpg'\n",
    "#prediction_image = 'img/cat.png'\n",
    "label, confidence = infer(prediction_image)\n",
    "print(label)\n",
    "print(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
